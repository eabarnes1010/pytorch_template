{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchinfo\n",
    "import importlib as imp\n",
    "import json\n",
    "\n",
    "import data_loader.data_loader as data_loader\n",
    "from trainer.trainer import Trainer\n",
    "from model.model import TorchModel\n",
    "from utils import utils\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.set_warn_always(False)\n",
    "\n",
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"xarray version = {xr.__version__}\")\n",
    "print(f\"pytorch version = {torch.__version__}\")\n",
    "\n",
    "# https://github.com/victoresque/pytorch-template/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.get_config(\"exp_test\")\n",
    "\n",
    "# TODO: check Shash skewness calculations...might be wrong!\n",
    "# TODO: move to new project\n",
    "# TODO: make data class for lats and lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config[\"seed\"])\n",
    "torch.cuda.manual_seed(config[\"seed\"])\n",
    "np.random.seed(config[\"seed\"])\n",
    "random.seed(config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Setup the Data\n",
    "trainset = data_loader.CustomData(\n",
    "    config[\"data_loader\"][\"data_dir\"] + \"train_data.pickle\"\n",
    ")\n",
    "valset = data_loader.CustomData(config[\"data_loader\"][\"data_dir\"] + \"val_data.pickle\")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "# Setup the Model\n",
    "model = TorchModel(config=config[\"arch\"], target=trainset.target)\n",
    "model.freeze_layers(freeze_id=\"tau\")\n",
    "optimizer = getattr(torch.optim, config[\"optimizer\"][\"type\"])(\n",
    "    model.parameters(), **config[\"optimizer\"][\"args\"]\n",
    ")\n",
    "criterion = getattr(module_loss, config[\"criterion\"])()\n",
    "metric_funcs = [getattr(module_metric, met) for met in config[\"metrics\"]]\n",
    "\n",
    "# Build the trainer\n",
    "device = utils.prepare_device(config[\"device\"])\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    metric_funcs,\n",
    "    optimizer,\n",
    "    max_epochs=config[\"trainer\"][\"max_epochs\"],\n",
    "    data_loader=train_loader,\n",
    "    validation_data_loader=val_loader,\n",
    "    device=device,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Visualize the model\n",
    "torchinfo.summary(\n",
    "    model,\n",
    "    [\n",
    "        trainset.input[: config[\"data_loader\"][\"batch_size\"]].shape,\n",
    "        trainset.input_unit[: config[\"data_loader\"][\"batch_size\"]].shape,\n",
    "    ],\n",
    "    verbose=0,\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\"),\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "model = model.to(device)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.log.history.keys())\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, m in enumerate((\"loss\", *config[\"metrics\"])):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.plot(trainer.log.history[\"epoch\"], trainer.log.history[m], label=m)\n",
    "    plt.plot(\n",
    "        trainer.log.history[\"epoch\"], trainer.log.history[\"val_\" + m], label=\"val_\" + m\n",
    "    )\n",
    "    plt.axvline(\n",
    "        x=trainer.early_stopper.best_epoch, linestyle=\"--\", color=\"k\", linewidth=0.75\n",
    "    )\n",
    "    plt.title(m)\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.Tensor(valset.input[:3]).to(device)\n",
    "input_unit = torch.Tensor(valset.input_unit[:3]).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(input, input_unit)\n",
    "output = output.cpu().numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shash.shash_torch\n",
    "from shash.shash_torch import Shash\n",
    "\n",
    "imp.reload(shash.shash_torch)\n",
    "\n",
    "sample = 1\n",
    "x = np.arange(-13, 13, 0.01)\n",
    "dist = Shash(output)\n",
    "p = dist.prob(x)\n",
    "\n",
    "plt.plot(x, p)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-torch-sonoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
